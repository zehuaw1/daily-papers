name: Daily ArXiv Paper Digest

on:
  schedule:
    # Run at 9:00 AM Eastern Time (Boston) every day
    # Eastern Time is UTC-5 (Standard) or UTC-4 (Daylight Saving)
    # To ensure 9:00 AM ET, set cron to 13:00 UTC (during DST, Mar-Nov) and 14:00 UTC (Standard, Nov-Mar)
    # GitHub Actions does not support time zone in cron, so use 13:00 UTC for most of the year (DST)
    - cron: '0 13 * * *'

  # Allow manual trigger for testing
  workflow_dispatch:

jobs:
  fetch-and-send:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: Generate config.py from secrets
      env:
        GOOGLE_GEMINI_API_KEY: ${{ secrets.GOOGLE_GEMINI_API_KEY }}
        EMAIL_SENDER: ${{ secrets.EMAIL_SENDER }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
        RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
        RECIPIENT_NAME: ${{ secrets.RECIPIENT_NAME }}
      run: |
        cat > config.py << 'EOF'
        # ==============================================================================
        # ArXiv Pusher Configuration (Generated by GitHub Actions)
        # ==============================================================================

        # ==============================================================================
        # AI Model Configuration
        # ==============================================================================

        # Google Gemini API (OpenAI-compatible endpoint)
        AI_CONFIG = {
            "api_key": "${GOOGLE_GEMINI_API_KEY}",
            "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
            "model": "gemini-2.5-flash",

            # Pricing (for cost tracking) - Gemini 2.5 Flash pricing (USD)
            "price_per_million_input_tokens": 0.30,  # USD
            "price_per_million_output_tokens": 2.50,  # USD
        }

        # DeepSeek API (commented out)
        # AI_CONFIG = {
        #     "api_key": "${DEEPSEEK_API_KEY}",
        #     "base_url": "https://api.deepseek.com",
        #     "model": "deepseek-chat",
        #
        #     # Pricing (for cost tracking) - DeepSeek V3 pricing
        #     "price_per_million_input_tokens": 2.00,  # CNY
        #     "price_per_million_output_tokens": 3.00,  # CNY
        # }

        # ==============================================================================
        # Email Server Configuration
        # ==============================================================================
        EMAIL_SERVER_CONFIG = {
            "sender": "${EMAIL_SENDER}",
            "password": "${EMAIL_PASSWORD}",
            "smtp_server": "smtp.gmail.com",
            "smtp_port": 587,
            "use_tls": True,
        }

        # ==============================================================================
        # General Configuration
        # ==============================================================================
        GENERAL_CONFIG = {
            "days_lookback": 1,
            "max_papers_per_user": 5,
            "max_text_length": 100000,

            # Social Feed Integration (FREE)
            "enable_huggingface": True,
            "huggingface_sort": None,  # "trending" or None for daily papers
        }

        # ==============================================================================
        # Default Prompts
        # ==============================================================================

        DEFAULT_FILTER_PROMPT = """You are an academic expert in AI/ML. Determine whether the following paper abstract relates to **one or more** of the research areas listed below. Points that are noted (*) are especially valued, prioritized.
        
        ---
        
        ### Language Models & Reasoning
        - Large Language Models (LLMs)
        - Reasoning (*) and agentic behavior (e.g., planning, tool use, self-reflection)
        - Foundation models and scaling laws
        - Memory-augmented architectures (e.g., RetNet, Mamba) (*)
        - Test-time compute scaling and adaptation (*)
        - Fast fine-tuning methods (e.g., LoRA, IA³) (*)
        
        ---
        
        ### Learning & Optimization
        - Reinforcement Learning (RL) (*)
        - Multi-agent RL and multi-agent AI environments (*)
        - Self-play or auto-curriculum RL for reasoning (*)
        - Scaling laws for RL
        - Neural architecture search (including continuous controllers)
        
        ---
        
        ### Generative & Multimodal Modeling
        - Generative models (e.g., diffusion models, flow matching) (*)
        - Diffusion Transformers (DiTs)
        - World models and world simulators (*)
        - 3D vision, scene understanding, and neural field representations, but the field needs to be truly novel
        - Multimodal or generalist agents (*)
        
        ---
        
        ### Embodiment, Physics & Graphics
        - Robotics and embodied AI (Physical AI) (*)
        - AI for physics or physics-informed models
        - Differentiable simulation or sim-to-real transfer
        - Computer graphics near AI (e.g., neural rendering, differentiable graphics, AI-based simulation or animation)
        
        ---
        
        ### Systems & Open Research
        - Open-source frontier models
        - Efficient or scalable model infrastructure
        
        ---
        
        ### Frontier & Highly Innovative Work
        - Any AI/ML research that represents a **notably novel, creative, or groundbreaking direction**, even if it does not cleanly fit into the categories above. (*)
        
        ---
        
        EXCLUDE papers that are primarily about:
        - Applications of AI/ML to specific domains (e.g., healthcare, finance) without novel AI/ML methods
        - Benchmarks or datasets
        - AI for chemistry or biology
        - Survey or benchmarking suites
        
        **Abstract:**
        {abstract}
        
        **Instruction:**
        Respond with **only** “yes” or “no”."""

        DEFAULT_SUMMARY_PROMPT = """You are an academic paper assistant. Your task is to provide a **concise, structured, and technically precise summary** of the following AI/ML paper in English.
        
        Include the following sections:
        
        1. **Key Contributions**
           - List 2-3 core contributions of the paper.
           - Focus on what is *novel* or *distinctive* compared to prior work.
        
        2. **Methodology**
           - Summarize the main approach, model architecture, or algorithmic pipeline.
           - Include key equations using Unicode math symbols with inline code formatting (see formatting instructions below).
        
        3. **Results**
           - Highlight major experimental outcomes and quantitative improvements.
           - Specify datasets or benchmarks if mentioned.
        
        4. **Significance**
           - Explain the broader impact or importance of the work.
           - Optionally include how it relates to trends in AI/ML research.
        
        **Paper Content:**
        {text}
        
        **Formatting Instructions:**
        - Respond in clear, professional **markdown** using bullet points and short paragraphs
        - **IMPORTANT**: Do NOT use LaTeX notation (e.g., $\theta$, $\mathbb{{E}}$)
        - **For equations**: Use Unicode math symbols with inline code formatting
          - Example: `L(θ) = -∑ᵢ log p(xᵢ|θ)` instead of LaTeX
          - Common symbols: α β γ δ ε θ λ μ σ π ∑ ∏ ∫ ∇ ∂ ≈ ≤ ≥ ∈ ⊥ ×
          - Use subscripts/superscripts when available: x₁, x², etc.
          - Use inline code backticks for formulas: `equation here`
        - Avoid speculation or commentary not supported by the text"""

        DEFAULT_RANKING_PROMPT = """You are an AI research assistant helping to prioritize papers for detailed review.
        
        Based on the user's research interests below, select the TOP {max_papers} most valuable and relevant papers from the list.
        
        **User's Research Interests:**
        {interests}
        
        **Available Papers ({num_papers} total):**
        
        {papers_list}
        
        **Task:**
        Select the {max_papers} most valuable papers based on: (decreasing priority)
        1. Novelty and potential impact
        2. Social engagement (upvotes, stars) as a secondary signal
        3. Relevance to the user's research interests
        4. Methodological rigor and contribution
        
        **Instructions:**
        First, reason through your selection process. Explain why you're choosing certain papers.
        Then, on the LAST LINE of your response, output the selected paper numbers as a comma-separated list.
        
        **Format:**
        [Your reasoning here...]
        
        SELECTED: 1,5,12,3,7"""

        # ==============================================================================
        # User Configurations
        # ==============================================================================
        USERS_CONFIG = [
            {
                "name": "${RECIPIENT_NAME}",
                "email": "${RECIPIENT_EMAIL}",
                "arxiv_categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.NE", "cs.RO", "cs.MA", "cs.GR"],
            },
        ]
        EOF
        echo "✅ config.py generated successfully"

    - name: Run ArXiv Pusher
      run: |
        python3 main.py

    - name: Upload logs as artifact (on failure)
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: arxiv-pusher-logs
        path: arxiv_pusher.log
        retention-days: 7
